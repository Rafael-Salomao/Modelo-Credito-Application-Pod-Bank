{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["HztzQsqd2fGm","nNqcWIWD35qy"],"authorship_tag":"ABX9TyNiavnxZ2KOafByImD4FH2I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Feature Engineering - POS_CASH_balance**"],"metadata":{"id":"4tHwliUyvJ8i"}},{"cell_type":"markdown","source":["## **Lendo dados com Spark**"],"metadata":{"id":"od3ZFosjvNl7"}},{"cell_type":"markdown","source":["### **Importar Bibliotecas**"],"metadata":{"id":"yFjYLvapvOHf"}},{"cell_type":"code","source":["!pip install boto3\n","!pip install s3fs\n","!pip install Pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6T75HLuNSZ9y","executionInfo":{"status":"ok","timestamp":1701469223407,"user_tz":180,"elapsed":53730,"user":{"displayName":"Rafael Salomao","userId":"07380706284005681115"}},"outputId":"36d99cdd-704c-4a34-dd2b-387f5af24752"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting boto3\n","  Downloading boto3-1.33.6-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore<1.34.0,>=1.33.6 (from boto3)\n","  Downloading botocore-1.33.6-py3-none-any.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.9.0,>=0.8.2 (from boto3)\n","  Downloading s3transfer-0.8.2-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.0,>=1.33.6->boto3) (2.8.2)\n","Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.0,>=1.33.6->boto3) (2.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.6->boto3) (1.16.0)\n","Installing collected packages: jmespath, botocore, s3transfer, boto3\n","Successfully installed boto3-1.33.6 botocore-1.33.6 jmespath-1.0.1 s3transfer-0.8.2\n","Collecting s3fs\n","  Downloading s3fs-2023.10.0-py3-none-any.whl (28 kB)\n","Collecting aiobotocore~=2.7.0 (from s3fs)\n","  Downloading aiobotocore-2.7.0-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fsspec==2023.10.0 (from s3fs)\n","  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from s3fs) (3.9.1)\n","Collecting botocore<1.31.65,>=1.31.16 (from aiobotocore~=2.7.0->s3fs)\n","  Downloading botocore-1.31.64-py3-none-any.whl (11.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore~=2.7.0->s3fs) (1.14.1)\n","Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore~=2.7.0->s3fs)\n","  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.0.3)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.31.65,>=1.31.16->aiobotocore~=2.7.0->s3fs) (1.0.1)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.31.65,>=1.31.16->aiobotocore~=2.7.0->s3fs) (2.8.2)\n","Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.31.65,>=1.31.16->aiobotocore~=2.7.0->s3fs) (2.0.7)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.31.65,>=1.31.16->aiobotocore~=2.7.0->s3fs) (1.16.0)\n","Installing collected packages: fsspec, aioitertools, botocore, aiobotocore, s3fs\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2023.6.0\n","    Uninstalling fsspec-2023.6.0:\n","      Successfully uninstalled fsspec-2023.6.0\n","  Attempting uninstall: botocore\n","    Found existing installation: botocore 1.33.6\n","    Uninstalling botocore-1.33.6:\n","      Successfully uninstalled botocore-1.33.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","boto3 1.33.6 requires botocore<1.34.0,>=1.33.6, but you have botocore 1.31.64 which is incompatible.\n","gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\n","s3transfer 0.8.2 requires botocore<2.0a.0,>=1.33.2, but you have botocore 1.31.64 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiobotocore-2.7.0 aioitertools-0.11.0 botocore-1.31.64 fsspec-2023.10.0 s3fs-2023.10.0\n","Collecting Pyspark\n","  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from Pyspark) (0.10.9.7)\n","Building wheels for collected packages: Pyspark\n","  Building wheel for Pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=d22e3ceaa87aa7f6ca6c54b7d452f4ff59787cb4029490d435d38bcadfd0c1a3\n","  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n","Successfully built Pyspark\n","Installing collected packages: Pyspark\n","Successfully installed Pyspark-3.5.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import boto3\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, when, round"],"metadata":{"id":"XT-_EpZoSYxh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName('Feature Engineering').getOrCreate()\n","spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"id":"JmZDkHJ3vSq8","executionInfo":{"status":"ok","timestamp":1701469234141,"user_tz":180,"elapsed":10249,"user":{"displayName":"Rafael Salomao","userId":"07380706284005681115"}},"outputId":"9be7e104-f2de-4d7e-ffc2-9a39ee891e10"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7ecaf61d4850>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://6e6b1c3b7119:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Feature Engineering</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# S3_DATA_SOURCE_PATH = 's3://pod-academy-analise-de-credito-para-fintech/dados/bureau_balance.csv'\n","# S3_DATA_OUTPUT_PATH = 's3://pod-academy-analise-de-credito-para-fintech/feature-engineering/01-Bureau/ábt_bureau_balance.parquet'\n","\n","# # S3 credentials\n","# AWS_ACCESS_KEY_ID = 'AKIAYTYOYG7SCH7IJSEG'\n","# AWS_SECRET_ACCESS_KEY = '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'\n","\n","# # Create a SparkSession\n","# print(\"Creating SparkSession...\")\n","# spark = SparkSession.builder.appName('GenerateAndProcessData') \\\n","#     .config('spark.hadoop.fs.s3a.access.key', AWS_ACCESS_KEY_ID) \\\n","#     .config('spark.hadoop.fs.s3a.secret.key', AWS_SECRET_ACCESS_KEY) \\\n","#     .getOrCreate()"],"metadata":{"id":"edfmebArSb6H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Importar tabela 'POS_CASH_balance'.**"],"metadata":{"id":"4qHTPNVsvcBU"}},{"cell_type":"markdown","source":["### **Importar .csv do colab usando PySpark.**"],"metadata":{"id":"PClChlqyvpIA"}},{"cell_type":"code","source":["# Caminho para ler o arquivo CSV localmente no Colab\n","path = \"/content/POS_CASH_balance.csv\"\n","\n","# Ler o arquivo de descrição das colunas\n","POS_CASH_balance_00 = spark.read.csv(path, header=True)\n","\n","# Mostrar número de linhas\n","POS_CASH_balance_00.count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"JdmyXMPHSdCm","executionInfo":{"status":"error","timestamp":1701469234795,"user_tz":180,"elapsed":669,"user":{"displayName":"Rafael Salomao","userId":"07380706284005681115"}},"outputId":"bab910c8-c758-4180-9d31-6b4f17929228"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-3cc51acacf43>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Ler o arquivo de descrição das colunas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mPOS_CASH_balance_00\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Mostrar número de linhas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/POS_CASH_balance.csv."]}]},{"cell_type":"code","source":["# # Read the data from the S3 bucket\n","# print(\"Reading data from S3...\")\n","# POS_CASH_balance_00 = spark.read.csv(S3_DATA_SOURCE_PATH, header=True)\n","\n","# # Mostrar número de linhas\n","# POS_CASH_balance_00.count()"],"metadata":{"id":"LQBfyfL5varz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["POS_CASH_balance_00.show(truncate=False)"],"metadata":{"id":"V0PigFk3Sht1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["POS_CASH_balance_00.printSchema()"],"metadata":{"id":"nMaYaAklSkR4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Comentário**\n","\n","- Cada \"SK_ID_PREV\" se refere a um único \"SK_ID_CURR\".\n","\n","- Um \"SK_ID_CURR\" pode corresponder a diferentes \"SK_ID_PREV\".\n","\n","- Ou seja, podemos referenciar as variáveis criadas com a tabela \"application\", assim como, a tabela \"previous_application\"."],"metadata":{"id":"UBWBUAWvzgEE"}},{"cell_type":"code","source":["POS_CASH_balance_00 = spark.sql('''\n","SELECT\n","  *\n","FROM\n","  POS_CASH_balance\n","WHERE\n","  SK_ID_CURR = '405549'\n","''')\n","\n","POS_CASH_balance_00.show()"],"metadata":{"id":"79sMriPIv-FJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Contar valores distintos da variável SK_ID_CURR\n","qtde_distinct_sk_id_curr = spark.sql('''\n","SELECT\n","  COUNT(DISTINCT SK_ID_CURR) AS qtde_distinct_sk_id_curr\n","FROM\n","  POS_CASH_balance\n","''')\n","\n","# Exibir a quantidade de valores distintos\n","qtde_distinct_sk_id_curr.show()"],"metadata":{"id":"n9nAUUAfFr2R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Criação de variáveis preditivas**"],"metadata":{"id":"hEhyFO0X0Tee"}},{"cell_type":"markdown","source":["## **POS_CASH_balance**"],"metadata":{"id":"4eifB3GA0WeW"}},{"cell_type":"code","source":["# Definir funções de agregações desejadas\n","agg = ['SUM', 'MAX', 'MIN', 'AVG']\n","\n","var_categoricas = ['NAME_CONTRACT_STATUS']\n","var_numericas = ['CNT_INSTALMENT', 'CNT_INSTALMENT_FUTURE', 'MONTHS_BALANCE', 'SK_DPD', 'SK_DPD_DEF']\n","\n","# Definir flags de meses\n","meses_flag = ['ultimos_3_meses_flag', 'ultimos_6_meses_flag', 'ultimos_9_meses_flag', 'ultimos_12_meses_flag']"],"metadata":{"id":"p2A83FTh0tw9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["POS_CASH_balance_00.createOrReplaceTempView('POS_CASH_balance_00')"],"metadata":{"id":"q68Y2hfHSuj5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Criando flags de janela para histórico:**\n","\n","- últimos 3 meses\n","\n","- últimos 6 meses\n","\n","- últimos 9 meses\n","\n","- últimos 12 meses"],"metadata":{"id":"Q5e3jgLO00b4"}},{"cell_type":"code","source":["POS_CASH_balance_01 = spark.sql(\"\"\"\n","SELECT\n","    *,\n","    CASE\n","        WHEN MONTHS_BALANCE BETWEEN MAX(MONTHS_BALANCE) OVER (PARTITION BY `SK_ID_CURR`) - 3 AND MAX(MONTHS_BALANCE) OVER (PARTITION BY `SK_ID_CURR`) THEN 1\n","        ELSE 0\n","    END AS ultimos_3_meses_flag,\n","    CASE\n","        WHEN MONTHS_BALANCE BETWEEN MAX(MONTHS_BALANCE) OVER (PARTITION BY `SK_ID_CURR`) - 6 AND MAX(MONTHS_BALANCE) OVER (PARTITION BY `SK_ID_CURR`) THEN 1\n","        ELSE 0\n","    END AS ultimos_6_meses_flag,\n","    CASE\n","        WHEN MONTHS_BALANCE BETWEEN MAX(MONTHS_BALANCE) OVER (PARTITION BY `SK_ID_CURR`) - 6 AND MAX(MONTHS_BALANCE) OVER (PARTITION BY `SK_ID_CURR`) THEN 1\n","        ELSE 0\n","    END AS ultimos_9_meses_flag,\n","    CASE\n","        WHEN MONTHS_BALANCE BETWEEN MAX(MONTHS_BALANCE) OVER (PARTITION BY `SK_ID_CURR`) - 12 AND MAX(MONTHS_BALANCE) OVER (PARTITION BY `SK_ID_CURR`) THEN 1\n","        ELSE 0\n","    END AS ultimos_12_meses_flag\n","FROM POS_CASH_balance_00\n","ORDER BY `SK_ID_CURR`, MONTHS_BALANCE;\n","\"\"\")\n","\n","POS_CASH_balance_01.createOrReplaceTempView(\"POS_CASH_balance_01\")\n","POS_CASH_balance_01.count()"],"metadata":{"id":"9NAeH-gIt6Ww","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701123088246,"user_tz":180,"elapsed":7562,"user":{"displayName":"Rafael Salomao","userId":"07380706284005681115"}},"outputId":"e821f5db-367b-4608-9caf-93070442ffb1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10001358"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# POS_CASH_balance_01.show()"],"metadata":{"id":"4clzeb881nBs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Criando variáveis explicativas de primeira camada**\n","\n","- usar média, mínimo, soma, máximo\n","- considerar variáveis categóricas e variáveis numéricas"],"metadata":{"id":"iDJhEdNH017K"}},{"cell_type":"markdown","source":["### **Gerar variáveis.**"],"metadata":{"id":"fjOUR_1w03Ux"}},{"cell_type":"code","source":["# Importar SparkSession\n","from pyspark.sql import SparkSession\n","\n","# Criar uma sessão do Spark\n","spark = SparkSession.builder.appName(\"AdaptacaoCodigo\").getOrCreate()\n","\n","df_original_spark = POS_CASH_balance_01\n","\n","# Inicializar o contador\n","contador_resultados = 0\n","\n","# Criar lista para armazenar os resultados\n","resultados = []\n","\n","for ag in agg:\n","    for var_cat in var_categoricas:\n","        # Filtrar valores distintos não nulos\n","        distinct_values = df_original_spark.select(var_cat).distinct().na.drop(subset=[var_cat]).rdd.flatMap(lambda x: x).collect()\n","\n","        for dom_cat_value in distinct_values:\n","            for var_numerica in var_numericas:\n","                resultado = f\"ROUND({ag}(CASE WHEN {var_cat} = '{dom_cat_value}' THEN {var_numerica} ELSE NULL END), 2) as {ag.lower()}_{var_numerica.lower()[:5]}_{var_cat.lower()[:4]}_{dom_cat_value.lower()[:3].replace(' ', '_')},\"\n","\n","                # Adicionar o resultado à lista\n","                resultados.append(resultado)\n","\n","                for mes_flag in meses_flag:\n","                    resultado = f\"ROUND({ag}(CASE WHEN {var_cat} = '{dom_cat_value}' AND {mes_flag} = 1 THEN {var_numerica} ELSE NULL END), 2) as {ag.lower()}_U{mes_flag.split('_')[1]}M_{var_numerica.lower()[:5]}_{var_cat.lower()[:4]}_{dom_cat_value.lower()[:3].replace(' ', '_')},\"\n","\n","                    # Adicionar o resultado à lista\n","                    resultados.append(resultado)\n","\n","                    # Incrementar o contador\n","                    contador_resultados += 1\n","\n","# Printar o total de combinações\n","print(f\"Total de combinações: {contador_resultados}\")\n"],"metadata":{"id":"2J7vvKvAAL32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inicializa a lista para armazenar os resultados\n","resultados_formatados = []\n","\n","# Se há pelo menos um resultado na lista\n","if resultados:\n","    # Remove a vírgula do último item\n","    resultados[-1] = resultados[-1].rstrip(',')\n","\n","    # Adiciona os resultados formatados à lista\n","    resultados_formatados.extend(resultados)\n","\n","    # Une a lista em uma string usando uma quebra de linha como separador\n","    resultados_str = '\\n'.join(resultados_formatados)\n","    # print(resultados_str)\n","else:\n","    resultados_str = \"A lista de resultados está vazia.\""],"metadata":{"id":"KHejbLJWLEbX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Colar variáveis criadas no código PySpark-SQL.**"],"metadata":{"id":"oN3MvXAz1NM5"}},{"cell_type":"code","source":["POS_CASH_balance_02 = spark.sql(f'''\n","SELECT\n","  SK_ID_CURR as SK_ID_CURR_POS_CASH_balance,\n","  {resultados_str}\n","FROM\n","  POS_CASH_balance_01\n","GROUP BY\n","  SK_ID_CURR\n","''')\n","\n","POS_CASH_balance_02.createOrReplaceTempView(\"POS_CASH_balance_02\")\n","POS_CASH_balance_02.count()"],"metadata":{"id":"AKzarXkyTBOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(POS_CASH_balance_02.columns))"],"metadata":{"id":"KNC_lmORXd-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# POS_CASH_balance_02.show()"],"metadata":{"id":"QUsDQRFv1d3v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Criando variáveis explicativas de segunda camada**\n","\n","- Razão entre variáveis históricas"],"metadata":{"id":"HztzQsqd2fGm"}},{"cell_type":"code","source":["# ID = 'SK_ID_CURR_POS_CASH_balance'\n","\n","# # Obter o esquema do DataFrame\n","# schema = POS_CASH_balance_02.schema\n","\n","# # Extrair nomes das colunas excluindo \"SK_ID_BUREAU_b\"\n","# colunas_originais = [col.name for col in schema if col.name != ID]\n","\n","# # Imprimir a lista de nomes das colunas\n","# print(colunas_originais)"],"metadata":{"id":"ewIvglO42fwz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Gerar variáveis.**"],"metadata":{"id":"Dcy-y0kA2oKz"}},{"cell_type":"code","source":["# # Inicializar o contador\n","# contador_resultados = 0\n","\n","# # Criar lista para armazenar os resultados\n","# resultados = []\n","\n","# # Criar novas colunas relacionadas\n","# for i in range(len(colunas_originais)):\n","#     for j in range(i+1, len(colunas_originais)):\n","#         coluna_i = colunas_originais[i]\n","#         coluna_j = colunas_originais[j]\n","#         nova_coluna_nome = f\"{coluna_i.split('_')[0]}_{coluna_j.split('_')[0]}_{coluna_i[4:]}_{coluna_j.split('_')[-1]}\"\n","#         resultado = f\"CASE WHEN {coluna_j} = 0 THEN NULL ELSE ROUND({coluna_i} / {coluna_j}, 2) END AS {nova_coluna_nome},\"\n","\n","#         # Adicionar o resultado à lista\n","#         resultados.append(resultado)\n","\n","#         # Incrementar o contador\n","#         contador_resultados += 1\n","\n","# # Printar o total de combinações\n","# print(f\"Total de combinações: {contador_resultados}\")"],"metadata":{"id":"ePHI5s3E2ojB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Inicializa a lista para armazenar os resultados\n","# resultados_formatados = []\n","\n","# # Se há pelo menos um resultado na lista\n","# if resultados:\n","#     # Remove a vírgula do último item\n","#     resultados[-1] = resultados[-1].rstrip(',')\n","\n","#     # Adiciona os resultados formatados à lista\n","#     resultados_formatados.extend(resultados)\n","\n","#     # Une a lista em uma string usando uma quebra de linha como separador\n","#     resultados_str = '\\n'.join(resultados_formatados)\n","#     # print(resultados_str)\n","# else:\n","#     resultados_str = \"A lista de resultados está vazia.\""],"metadata":{"id":"MG-yo3MKRp1f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Colar variáveis criadas no código PySpark-SQL.**"],"metadata":{"id":"nNqcWIWD35qy"}},{"cell_type":"code","source":["# POS_CASH_balance_03 = spark.sql(f'''\n","# SELECT\n","#   *,\n","#   {resultados_str}\n","# FROM\n","#   POS_CASH_balance_02\n","# ''')\n","\n","# POS_CASH_balance_03.createOrReplaceTempView(\"POS_CASH_balance_03\")\n","# POS_CASH_balance_03.count()"],"metadata":{"id":"VbQaLtnpXksu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# POS_CASH_balance_03.show()"],"metadata":{"id":"ycXDl60C-1To"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(len(POS_CASH_balance_03.columns))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNsfI0ihG-Eu","executionInfo":{"status":"ok","timestamp":1701094097181,"user_tz":180,"elapsed":1128,"user":{"displayName":"Rafael Salomao","userId":"07380706284005681115"}},"outputId":"f0132457-399d-48e4-c3d8-d9e8e63d0ad2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["16291\n"]}]},{"cell_type":"markdown","source":["## **Salvando tabela no diretório do Drive e S3.**"],"metadata":{"id":"SszyD2MBHMaS"}},{"cell_type":"code","source":["abt_POS_CASH_balance = POS_CASH_balance_02"],"metadata":{"id":"_UM_DPeCHYe0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save to parquet\n","abt_POS_CASH_balance.write.mode(\"overwrite\").parquet(\"/content/abt_POS_CASH_balance.parquet\")"],"metadata":{"id":"irqudgeiXsZb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pip list --format=freeze > '/content/requirements.txt'"],"metadata":{"id":"_tltz3HTXtVN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Save the processed data to an S3 bucket\n","# print(\"Writing processed data to S3...\")\n","# abt_POS_CASH_balance.write.mode('overwrite').parquet(S3_DATA_OUTPUT_PATH)"],"metadata":{"id":"m1Znkd7eIWw0"},"execution_count":null,"outputs":[]}]}